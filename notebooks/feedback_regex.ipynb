{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feedback_regex.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO09V+Xi3BvRzN8SJY0QLhE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekunnii/chatbot_feeder/blob/master/notebooks/feedback_regex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol-acS1eajNt",
        "colab_type": "text"
      },
      "source": [
        "# Use regex to process the feedback\n",
        "\n",
        "This is the baseline for self-feeding chatbot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBHKBWolaY4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7Q_NKQYxoTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLpEYPlYailO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET='/gdrive/My Drive/ParlAI/data/self_feeding'\n",
        "os.chdir(DATASET)\n",
        "os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5TlHsrMilXE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpwwa68aKpKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def processed_feedback(file_name, file_dir):\n",
        "    file_path = os.path.join(file_dir, file_name)\n",
        "    df = pd.read_json(file_path, lines=True)\n",
        "    response_list = df['response'].to_list()\n",
        "\n",
        "    processed_responses = []\n",
        "\n",
        "    for idx, sentence in enumerate(response_list):\n",
        "\n",
        "        match_choice = re.search('yes or no', sentence)\n",
        "        if match_choice:\n",
        "            processed_responses.append(\"yes\")\n",
        "            continue\n",
        "\n",
        "        match_greeting = re.search('greeting|hi |hello', sentence)\n",
        "        if match_greeting:\n",
        "            processed_responses.append(\"hello, how are you?\")\n",
        "            continue\n",
        "\n",
        "        match_job = re.search('job|career|living', sentence)\n",
        "        if match_job:\n",
        "            processed_responses.append(\"I am a teacher, what about you?\")\n",
        "            continue\n",
        "\n",
        "        match_mess = re.search('messed up',sentence)\n",
        "        if match_mess:\n",
        "            processed_responses.append(\"Sorry, I am not good at this topic. Do you want to talk about anything else?\")\n",
        "            continue\n",
        "\n",
        "        match_country = re.search('country',sentence)\n",
        "        if match_mess:\n",
        "            processed_responses.append(\"I am a robot, I don't live in any country\")\n",
        "            continue\n",
        "\n",
        "        match_filler = re.search('you could|you should|said|saying|say|tell|told|admit|ask|answer|talk|yes|no', sentence)\n",
        "\n",
        "        if match_filler: \n",
        "            # processed_sentence = sentence          \n",
        "            processed_sentence = re.sub(\"you could have|you should have|you could|you should\", '', sentence).strip()\n",
        "            processed_sentence = re.sub(\"^.*said|^.*saying|^.*say|^.*tell |^.*told |^.*admit |^.*asked |^.*ask |^.*answer |^.*answered |^.*talked |^.*talk \", '', processed_sentence).strip()\n",
        "            processed_sentence = re.sub(\"^.*about|^me |^of \", '', processed_sentence).strip()\n",
        "\n",
        "            piceses = processed_sentence.split(' or ')\n",
        "            processed_sentence = piceses[0].strip()\n",
        "            for piece in piceses:\n",
        "                piece = piece.strip()\n",
        "                if len(piece) > len(processed_sentence):\n",
        "                    processed_sentence = piece\n",
        "            # remove                \n",
        "            processed_sentence = re.sub(\"^if |^whether |^not \", '', processed_sentence).strip()\n",
        "\n",
        "            # replace subject\n",
        "            processed_sentence = re.sub(\"you \", 'i ', processed_sentence).strip()\n",
        "            processed_sentence = re.sub(\"you are |i are \", 'i am ', processed_sentence).strip()\n",
        "            processed_sentence = re.sub(\"your \", 'my ', processed_sentence).strip()        \n",
        "            processed_sentence = re.sub(\"you\\'ve \", 'i\\'ve ', processed_sentence).strip()\n",
        "            processed_sentence = re.sub(\"you were | i were\", 'i was', processed_sentence).strip()            \n",
        "            processed_sentence = re.sub(\"you're \", 'i\\'m ', processed_sentence).strip()\n",
        "\n",
        "            \n",
        "            # Remove starting space and comma\n",
        "            processed_sentence = re.sub(\"\\“|\\”\", '', processed_sentence).strip() \n",
        "            processed_sentence = processed_sentence.lstrip(':|,|\\\"|\\'|-|.| ')\n",
        "            processed_sentence = processed_sentence.rstrip('\\\"|\\'| ')\n",
        "\n",
        "            if len(processed_sentence) > 0:\n",
        "                processed_responses.append(processed_sentence)\n",
        "            else:\n",
        "                # print(processed_sentence,\"<<<<<<\", sentence)\n",
        "                processed_responses.append(sentence)\n",
        "\n",
        "            # print(processed_sentence,\"<<<<<<\", sentence)\n",
        "            s = processed_sentence + \"<<<<<<\" + sentence +'\\n'\n",
        "            fd_out.writelines(s)\n",
        "\n",
        "        else:\n",
        "            processed_responses.append(sentence)\n",
        "\n",
        "    df['response'] = processed_responses\n",
        "    file_name='regex_'+file_name\n",
        "    print(file_name)\n",
        "    df.to_json(file_name, orient='records',lines=True)\n",
        "        \n",
        "# Process all feedback files\n",
        "# file_list = ['train_fb.txt', 'train_fb_a.txt', 'train_fb_b.txt', 'test_fb.txt', 'valid_fb.txt']\n",
        "# file_dir = os.path.abspath(os.path.join(os.getcwd(), '..', 'self_feeding_bak'))\n",
        "\n",
        "file_list = ['train_fb.txt']\n",
        "file_dir = os.getcwd()\n",
        "\n",
        "\n",
        "with open('processed_feedback.txt', 'w') as fd_out:\n",
        "    for file_name in file_list:\n",
        "        processed_feedback(file_name, file_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUh2_Zaa5JuV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9f45b8dc-021c-4ef2-e53e-be141b6a2529"
      },
      "source": [
        "!wc -l train_fb.txt\n",
        "!wc -l processed_feedback.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "61339 train_fb.txt\n",
            "38105 processed_feedback.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZpAFD_oIP5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_json(\"train_fb.txt\", lines=True)\n",
        "response_list = df['response'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vvLDqdkIcfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open(\"regex_test.txt\", 'r') as f_in, open('processed_feedback.txt', 'w') as fd_out:\n",
        "#     lines = f_in.readlines()\n",
        "#     processed_responses = []\n",
        "#     for sentence in lines:\n",
        "#         sentence = sentence.strip()\n",
        "\n",
        "#         match_choice = re.search('yes or no', sentence)\n",
        "#         if match_choice:\n",
        "#             processed_responses.append(\"yes\")\n",
        "#             continue\n",
        "\n",
        "#         match_greeting = re.search('greeting|hi |hello', sentence)\n",
        "#         if match_greeting:\n",
        "#             processed_responses.append(\"Hello, how are you?\")\n",
        "#             continue\n",
        "\n",
        "#         match_job = re.search('job|career|living', sentence)\n",
        "#         if match_job:\n",
        "#             processed_responses.append(\"I am a teacher, what about you?\")\n",
        "#             continue\n",
        "\n",
        "#         match_mess = re.search('messed up',sentence)\n",
        "#         if match_mess:\n",
        "#             processed_responses.append(\"Sorry, I am not good at this topic. Do you want to talk about anything else?\")\n",
        "#             continue\n",
        "\n",
        "#         match_country = re.search('country',sentence)\n",
        "#         if match_mess:\n",
        "#             processed_responses.append(\"I am a robot, I don't live in any country\")\n",
        "#             continue\n",
        "\n",
        "#         match_filler = re.search('you could|you should|said|saying|say|tell|told|admit|ask|answer|talk|yes|no', sentence)\n",
        "\n",
        "#         if match_filler: \n",
        "#             # processed_sentence = sentence          \n",
        "#             processed_sentence = re.sub(\"you could have|you should have|you could|you should\", '', sentence).strip()\n",
        "#             processed_sentence = re.sub(\"^.*said|^.*saying|^.*say|^.*tell |^.*told |^.*admit |^.*asked |^.*ask |^.*answer |^.*answered |^.*talked |^.*talk |^.*that \", '', processed_sentence).strip()\n",
        "#             processed_sentence = re.sub(\"^.*about|^me|that\", '', processed_sentence).strip()\n",
        "\n",
        "#             piceses = processed_sentence.split(' or ')\n",
        "#             processed_sentence = piceses[0].strip()\n",
        "#             for piece in piceses:\n",
        "#                 piece = piece.strip()\n",
        "#                 if len(piece) > len(processed_sentence):\n",
        "#                     processed_sentence = piece\n",
        "#             # remove                \n",
        "#             processed_sentence = re.sub(\"^if|^whether|^not\", '', processed_sentence).strip()\n",
        "\n",
        "#             # replace subject\n",
        "#             processed_sentence = re.sub(\"you are \", 'i am ', processed_sentence).strip()\n",
        "#             processed_sentence = re.sub(\"your \", 'my ', processed_sentence).strip()        \n",
        "#             processed_sentence = re.sub(\"you\\'ve \", 'i\\'ve ', processed_sentence).strip()\n",
        "#             processed_sentence = re.sub(\"you were\", 'i was', processed_sentence).strip()\n",
        "#             processed_sentence = re.sub(\"you \", 'i ', processed_sentence).strip()\n",
        "#             processed_sentence = re.sub(\"you're \", 'i\\'m ', processed_sentence).strip()\n",
        "\n",
        "            \n",
        "#             # Remove starting space and comma\n",
        "#             processed_sentence = re.sub(\"\\“|\\”\", '', processed_sentence).strip() \n",
        "#             processed_sentence = processed_sentence.lstrip(':|,|\\\"|\\'|-|.| ')\n",
        "#             processed_sentence = processed_sentence.rstrip('\\\"|\\'| ')\n",
        "\n",
        "#             if len(processed_sentence) > 0:\n",
        "#                 processed_responses.append(processed_sentence)\n",
        "#             else:\n",
        "#                 processed_responses.append(sentence)\n",
        "\n",
        "#         else:\n",
        "#             processed_responses.append(sentence)\n",
        "             \n",
        "#     for res in processed_responses:\n",
        "#         fd_out.write(res+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}